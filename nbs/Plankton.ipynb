{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Bowl 2015\n",
    "\n",
    "## Organize Data\n",
    "\n",
    "- Create folder, then download files with kaggle-cli\n",
    "- data_dir should have subfolders train/ and test/ containing folders of images sorted by category, and 130400 test images, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, sys, shutil, random\n",
    "data_dir = '/home/ubuntu/fastai-data/plankton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Organize directories\n",
    "%cd $data_dir\n",
    "%mkdir results\n",
    "%mkdir valid\n",
    "%mkdir temp\n",
    "%mkdir temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path variables\n",
    "train_path = os.path.join(data_dir,'train')\n",
    "valid_path = os.path.join(data_dir,'valid')\n",
    "test_path = os.path.join(data_dir,'test')\n",
    "result_path = os.path.join(data_dir,'results')\n",
    "temp_path = os.path.join(data_dir,'temp')\n",
    "temp_path2 = os.path.join(data_dir,'temp2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code moves 1/5 of the total training images, selected at random, to the validation set. The distribution of both sets should be similar though slightly different, as this is a simple rather than stratified sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [os.path.join(valid_path,c,f) for c in os.listdir(train_path) for f in os.listdir(os.path.join(train_path,c))]\n",
    "files = random.sample(files, int(len(files)*0.2))\n",
    "\n",
    "for f in files:\n",
    "    if not os.path.exists(os.path.dirname(f)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(f))\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    \n",
    "    shutil.move(f.replace('/valid/','/train/'), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Move/Copy data into appropriate directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'test'\n",
    "%cd $data_dir\n",
    "%mv $name 'unknown'\n",
    "%mkdir $name\n",
    "%mv 'unknown' $name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisdir = '/home/ubuntu/fastai-notes/nbs/'\n",
    "%cd $thisdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.core import MaxoutDense\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Instantiate plotting tool\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [forums](http://forums.fast.ai/t/batch-size-effect-on-validation-accuracy/413) batch sizes of at least 64 is better for approximating true gradient (and I don't want to go higher as it would necesitate simplifying the model or reducing the image resolution to fit in memory). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration variables\n",
    "batch_size = 128\n",
    "val_batch_size = batch_size*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation reduces overfitting and is an essential component of most modern neural nets. The rotation should have worked fine but I decided more extreme augmentation was not that helpful as my network was not overfitting much, vertical and horizontal flipping should end up making similar transformations, and excessive augmentation will reduce convergence speed.\n",
    "\n",
    "The relatively small image size is so my network can reliably run without memory allocation problems, as that was a problem on my p2.xlarge instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24269 images belonging to 121 classes.\n",
      "Found 6067 images belonging to 121 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def get_batch2(dirname, temp_dir=None, augment=True, shuffle=True):\n",
    "    gen = image.ImageDataGenerator()\n",
    "    if augment:\n",
    "        gen = image.ImageDataGenerator(#rotation_range=360,\n",
    "                                       width_shift_range=0.05,\n",
    "                                       height_shift_range=0.05,\n",
    "                                       shear_range=0.10,\n",
    "                                       zoom_range=0.3,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True)\n",
    "\n",
    "    return gen.flow_from_directory(dirname,\n",
    "                                  target_size=(48,48),\n",
    "                                  class_mode='categorical',\n",
    "                                  color_mode='grayscale',\n",
    "                                  shuffle=shuffle,\n",
    "                                  save_to_dir=temp_dir,\n",
    "                                  batch_size=batch_size)\n",
    "\n",
    "batches = get_batch2(train_path, temp_dir=None)\n",
    "val_batches = get_batch2(valid_path, temp_dir=None, shuffle=True, augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify augmentation\n",
    "\n",
    "When my model was preforming poorly (~5% validation accuracy and stagnant from there) I suspected there might be a problem with the validation set construction and so was careful to check that the augmentation did not create drastic differences between the training and validation sets.\n",
    "\n",
    "#### Check min/max/mean statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    batch, labels = next(batches) # save 3 batches of images\n",
    "    print('TRAINING | max: {} min: {} mean: {}'.format(np.max(batch), np.min(batch), np.mean(batch)))\n",
    "    val_batch, labels = next(val_batches)\n",
    "    print('VALIDATE | max: {} min: {} mean: {}\\n'.format(np.max(val_batch), np.min(val_batch), np.mean(val_batch)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import random\n",
    "\n",
    "plots([image.load_img(os.path.join(temp_path, img)) for img in random.sample(os.listdir(temp_path), 8)])\n",
    "plots([image.load_img(os.path.join(temp_path2, img)) for img in random.sample(os.listdir(temp_path2), 8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show distribution of images\n",
    "train_dist = [len(os.listdir(os.path.join(train_path,c))) for c in os.listdir(train_path)]\n",
    "valid_dist = [len(os.listdir(os.path.join(valid_path,c))) for c in os.listdir(valid_path)]\n",
    "train_sum = sum(train_dist)\n",
    "valid_sum = sum(valid_dist)\n",
    "for i in range(121):\n",
    "    print('{:5.3f}% training vs {:5.3f}% validation'\n",
    "          .format(100*train_dist[i]/float(train_sum), 100*valid_dist[i]/float(valid_sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build convolutional model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My initial model was based off a description of the [winning architecture](http://benanne.github.io/2015/03/17/plankton.html), without the rotation pooling and rolling parts. This did not lead to very good preformance - while the training accuracy would increase (though it wasn't that high, maybe 20%) the validation accuracy would be stagnant and very low (~5%).\n",
    "\n",
    "After [asking around](http://forums.fast.ai/t/low-accuracy-but-overfitting/5537/11) I was advised to try building a very simple architecture and see if it worked at all. To my suprise one 512-param dense layer between an input batchnorm and output dense(121) was all that was needed for pretty good accuracy up to 40%, though it was clearly underfitting (training accuracy up to 10% lower than validation).\n",
    "\n",
    "I then found a [simpler model](https://github.com/hjweide/NDSB/blob/master/net24.py) that achieved top ten, implemented in lasagne, and basically copied it in keras. This seems to work pretty well, with ~74% validation accuracy after 200 epochs at the default 0.001 learning rate (though the lr isn't that meaningful as I'm using Adam). Running for 300 epochs doesn't seem to improve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_1 (BatchNorma (None, 1, 48, 48)     2           batchnormalization_input_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 256, 45, 45)   4352        batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "prelu_1 (PReLU)                  (None, 256, 45, 45)   518400      convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 256, 45, 45)   512         prelu_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 256, 22, 22)   0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 256, 22, 22)   0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 384, 20, 20)   885120      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "prelu_2 (PReLU)                  (None, 384, 20, 20)   153600      convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 384, 20, 20)   768         prelu_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 384, 10, 10)   0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 384, 10, 10)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 1024, 8, 8)    3539968     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "prelu_3 (PReLU)                  (None, 1024, 8, 8)    65536       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 1024, 8, 8)    2048        prelu_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 1024, 4, 4)    0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 1024, 4, 4)    0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 16384)         0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxoutdense_1 (MaxoutDense)      (None, 1024)          33556480    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "prelu_4 (PReLU)                  (None, 1024)          1024        maxoutdense_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 1024)          2048        prelu_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 1024)          0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxoutdense_2 (MaxoutDense)      (None, 1024)          2099200     dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "prelu_5 (PReLU)                  (None, 1024)          1024        maxoutdense_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 1024)          2048        prelu_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 1024)          0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 121)           124025      dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 40956155\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# super-simple model for testing\n",
    "# actually model copied from https://github.com/hjweide/NDSB/blob/master/net24.py\n",
    "model = Sequential([\n",
    "    BatchNormalization(axis=1, input_shape=(1,48,48)),\n",
    "    \n",
    "    Convolution2D(256,4,4,init='he_uniform'), # convolution layers\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D(strides=(2,2)),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Convolution2D(384,3,3,init='he_uniform'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D(strides=(2,2)),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Convolution2D(1024,3,3,init='he_uniform'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D(strides=(2,2)),\n",
    "    #Lambda(Maxout),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    MaxoutDense(1024, nb_feature=2, init='he_uniform'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    MaxoutDense(1024, nb_feature=2, init='he_uniform'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5,),\n",
    "    \n",
    "    Dense(121, activation='softmax', init='he_uniform')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7939 - acc: 0.7526 - val_loss: 0.9118 - val_acc: 0.7440\n",
      "Epoch 2/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7937 - acc: 0.7511 - val_loss: 0.9070 - val_acc: 0.7496\n",
      "Epoch 3/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7981 - acc: 0.7538 - val_loss: 0.9258 - val_acc: 0.7432\n",
      "Epoch 4/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.8011 - acc: 0.7477 - val_loss: 0.9096 - val_acc: 0.7397\n",
      "Epoch 5/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7933 - acc: 0.7522 - val_loss: 0.9262 - val_acc: 0.7416\n",
      "Epoch 6/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7831 - acc: 0.7516 - val_loss: 0.9077 - val_acc: 0.7432\n",
      "Epoch 7/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.8056 - acc: 0.7461 - val_loss: 0.8916 - val_acc: 0.7488\n",
      "Epoch 8/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7999 - acc: 0.7512 - val_loss: 0.9453 - val_acc: 0.7397\n",
      "Epoch 9/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7919 - acc: 0.7521 - val_loss: 0.8787 - val_acc: 0.7505\n",
      "Epoch 10/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7955 - acc: 0.7544 - val_loss: 0.9139 - val_acc: 0.7429\n",
      "Epoch 11/100\n",
      "24269/24269 [==============================] - 226s - loss: 0.8007 - acc: 0.7499 - val_loss: 0.9274 - val_acc: 0.7422\n",
      "Epoch 12/100\n",
      "24269/24269 [==============================] - 226s - loss: 0.7792 - acc: 0.7562 - val_loss: 0.9052 - val_acc: 0.7483\n",
      "Epoch 13/100\n",
      "24269/24269 [==============================] - 225s - loss: 0.8041 - acc: 0.7503 - val_loss: 0.8664 - val_acc: 0.7551\n",
      "Epoch 14/100\n",
      "24269/24269 [==============================] - 226s - loss: 0.7869 - acc: 0.7537 - val_loss: 0.9299 - val_acc: 0.7409\n",
      "Epoch 15/100\n",
      "24269/24269 [==============================] - 225s - loss: 0.7959 - acc: 0.7533 - val_loss: 0.9172 - val_acc: 0.7427\n",
      "Epoch 16/100\n",
      "24269/24269 [==============================] - 226s - loss: 0.7976 - acc: 0.7542 - val_loss: 0.8976 - val_acc: 0.7465\n",
      "Epoch 17/100\n",
      "24269/24269 [==============================] - 226s - loss: 0.7853 - acc: 0.7535 - val_loss: 0.9304 - val_acc: 0.7397\n",
      "Epoch 18/100\n",
      "24269/24269 [==============================] - 226s - loss: 0.7878 - acc: 0.7528 - val_loss: 0.9260 - val_acc: 0.7384\n",
      "Epoch 19/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7812 - acc: 0.7548 - val_loss: 0.9151 - val_acc: 0.7434\n",
      "Epoch 20/100\n",
      "24269/24269 [==============================] - 227s - loss: 0.7880 - acc: 0.7540 - val_loss: 0.9057 - val_acc: 0.7445\n",
      "Epoch 21/100\n",
      "24269/24269 [==============================] - 226s - loss: 0.7835 - acc: 0.7536 - val_loss: 0.9076 - val_acc: 0.7455\n",
      "Epoch 22/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7933 - acc: 0.7499 - val_loss: 0.9163 - val_acc: 0.7429\n",
      "Epoch 23/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7941 - acc: 0.7543 - val_loss: 0.9201 - val_acc: 0.7434\n",
      "Epoch 24/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7962 - acc: 0.7496 - val_loss: 0.8973 - val_acc: 0.7486\n",
      "Epoch 25/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7908 - acc: 0.7535 - val_loss: 0.9094 - val_acc: 0.7442\n",
      "Epoch 26/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7910 - acc: 0.7577 - val_loss: 0.9050 - val_acc: 0.7417\n",
      "Epoch 27/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7919 - acc: 0.7547 - val_loss: 0.8995 - val_acc: 0.7501\n",
      "Epoch 28/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7866 - acc: 0.7516 - val_loss: 0.8883 - val_acc: 0.7452\n",
      "Epoch 29/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7850 - acc: 0.7532 - val_loss: 0.9050 - val_acc: 0.7444\n",
      "Epoch 30/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7931 - acc: 0.7533 - val_loss: 0.9066 - val_acc: 0.7427\n",
      "Epoch 31/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7929 - acc: 0.7540 - val_loss: 0.9191 - val_acc: 0.7432\n",
      "Epoch 32/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7955 - acc: 0.7523 - val_loss: 0.9018 - val_acc: 0.7448\n",
      "Epoch 33/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.8059 - acc: 0.7512 - val_loss: 0.8993 - val_acc: 0.7467\n",
      "Epoch 34/100\n",
      "24269/24269 [==============================] - 231s - loss: 0.7874 - acc: 0.7580 - val_loss: 0.9167 - val_acc: 0.7396\n",
      "Epoch 35/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7986 - acc: 0.7552 - val_loss: 0.9102 - val_acc: 0.7444\n",
      "Epoch 36/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7796 - acc: 0.7551 - val_loss: 0.8986 - val_acc: 0.7422\n",
      "Epoch 37/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7971 - acc: 0.7503 - val_loss: 0.9100 - val_acc: 0.7439\n",
      "Epoch 38/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7948 - acc: 0.7506 - val_loss: 0.8964 - val_acc: 0.7495\n",
      "Epoch 39/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7835 - acc: 0.7561 - val_loss: 0.9129 - val_acc: 0.7388\n",
      "Epoch 40/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7878 - acc: 0.7550 - val_loss: 0.9077 - val_acc: 0.7404\n",
      "Epoch 41/100\n",
      "24269/24269 [==============================] - 227s - loss: 0.7859 - acc: 0.7535 - val_loss: 0.9170 - val_acc: 0.7450\n",
      "Epoch 42/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7923 - acc: 0.7533 - val_loss: 0.8829 - val_acc: 0.7448\n",
      "Epoch 43/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7811 - acc: 0.7525 - val_loss: 0.8993 - val_acc: 0.7453\n",
      "Epoch 44/100\n",
      "24269/24269 [==============================] - 227s - loss: 0.7918 - acc: 0.7552 - val_loss: 0.9100 - val_acc: 0.7447\n",
      "Epoch 45/100\n",
      "24269/24269 [==============================] - 227s - loss: 0.7933 - acc: 0.7506 - val_loss: 0.9152 - val_acc: 0.7442\n",
      "Epoch 46/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7817 - acc: 0.7549 - val_loss: 0.8904 - val_acc: 0.7472\n",
      "Epoch 47/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7826 - acc: 0.7547 - val_loss: 0.8938 - val_acc: 0.7475\n",
      "Epoch 48/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7845 - acc: 0.7554 - val_loss: 0.9174 - val_acc: 0.7379\n",
      "Epoch 49/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7893 - acc: 0.7544 - val_loss: 0.9028 - val_acc: 0.7440\n",
      "Epoch 50/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7923 - acc: 0.7515 - val_loss: 0.9003 - val_acc: 0.7458\n",
      "Epoch 51/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7890 - acc: 0.7524 - val_loss: 0.8999 - val_acc: 0.7465\n",
      "Epoch 52/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7868 - acc: 0.7556 - val_loss: 0.9268 - val_acc: 0.7358\n",
      "Epoch 53/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7908 - acc: 0.7551 - val_loss: 0.9116 - val_acc: 0.7435\n",
      "Epoch 54/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.8000 - acc: 0.7526 - val_loss: 0.9136 - val_acc: 0.7442\n",
      "Epoch 55/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7882 - acc: 0.7531 - val_loss: 0.8771 - val_acc: 0.7452\n",
      "Epoch 56/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7922 - acc: 0.7546 - val_loss: 0.9461 - val_acc: 0.7336\n",
      "Epoch 57/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7842 - acc: 0.7566 - val_loss: 0.8715 - val_acc: 0.7519\n",
      "Epoch 58/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7777 - acc: 0.7522 - val_loss: 0.9142 - val_acc: 0.7417\n",
      "Epoch 59/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7886 - acc: 0.7536 - val_loss: 0.9089 - val_acc: 0.7437\n",
      "Epoch 60/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7868 - acc: 0.7545 - val_loss: 0.9032 - val_acc: 0.7444\n",
      "Epoch 61/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7918 - acc: 0.7535 - val_loss: 0.9176 - val_acc: 0.7457\n",
      "Epoch 62/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7851 - acc: 0.7545 - val_loss: 0.9052 - val_acc: 0.7437\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24269/24269 [==============================] - 229s - loss: 0.7872 - acc: 0.7577 - val_loss: 0.9147 - val_acc: 0.7419\n",
      "Epoch 64/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7889 - acc: 0.7546 - val_loss: 0.9011 - val_acc: 0.7444\n",
      "Epoch 65/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7895 - acc: 0.7546 - val_loss: 0.8928 - val_acc: 0.7457\n",
      "Epoch 66/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7943 - acc: 0.7508 - val_loss: 0.9009 - val_acc: 0.7435\n",
      "Epoch 67/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7879 - acc: 0.7541 - val_loss: 0.9013 - val_acc: 0.7448\n",
      "Epoch 68/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7919 - acc: 0.7517 - val_loss: 0.9001 - val_acc: 0.7439\n",
      "Epoch 69/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7893 - acc: 0.7578 - val_loss: 0.9155 - val_acc: 0.7440\n",
      "Epoch 70/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7829 - acc: 0.7548 - val_loss: 0.8951 - val_acc: 0.7496\n",
      "Epoch 71/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7951 - acc: 0.7506 - val_loss: 0.8958 - val_acc: 0.7480\n",
      "Epoch 72/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7920 - acc: 0.7538 - val_loss: 0.9230 - val_acc: 0.7402\n",
      "Epoch 73/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7898 - acc: 0.7558 - val_loss: 0.9013 - val_acc: 0.7442\n",
      "Epoch 74/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7910 - acc: 0.7521 - val_loss: 0.9049 - val_acc: 0.7414\n",
      "Epoch 75/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7875 - acc: 0.7535 - val_loss: 0.8947 - val_acc: 0.7465\n",
      "Epoch 76/100\n",
      "24269/24269 [==============================] - 227s - loss: 0.7980 - acc: 0.7544 - val_loss: 0.8840 - val_acc: 0.7516\n",
      "Epoch 77/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7867 - acc: 0.7548 - val_loss: 0.9136 - val_acc: 0.7404\n",
      "Epoch 78/100\n",
      "24269/24269 [==============================] - 227s - loss: 0.7874 - acc: 0.7574 - val_loss: 0.8943 - val_acc: 0.7434\n",
      "Epoch 79/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.8043 - acc: 0.7530 - val_loss: 0.9024 - val_acc: 0.7452\n",
      "Epoch 80/100\n",
      "24269/24269 [==============================] - 227s - loss: 0.7903 - acc: 0.7542 - val_loss: 0.9110 - val_acc: 0.7465\n",
      "Epoch 81/100\n",
      "24269/24269 [==============================] - 227s - loss: 0.7787 - acc: 0.7596 - val_loss: 0.9213 - val_acc: 0.7427\n",
      "Epoch 82/100\n",
      "24269/24269 [==============================] - 227s - loss: 0.7800 - acc: 0.7561 - val_loss: 0.8809 - val_acc: 0.7465\n",
      "Epoch 83/100\n",
      "24269/24269 [==============================] - 225s - loss: 0.7832 - acc: 0.7528 - val_loss: 0.9052 - val_acc: 0.7437\n",
      "Epoch 84/100\n",
      "24269/24269 [==============================] - 227s - loss: 0.7824 - acc: 0.7515 - val_loss: 0.8945 - val_acc: 0.7493\n",
      "Epoch 85/100\n",
      "24269/24269 [==============================] - 226s - loss: 0.7890 - acc: 0.7555 - val_loss: 0.9178 - val_acc: 0.7383\n",
      "Epoch 86/100\n",
      "24269/24269 [==============================] - 227s - loss: 0.7880 - acc: 0.7542 - val_loss: 0.9005 - val_acc: 0.7463\n",
      "Epoch 87/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7784 - acc: 0.7542 - val_loss: 0.8974 - val_acc: 0.7417\n",
      "Epoch 88/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7953 - acc: 0.7514 - val_loss: 0.8969 - val_acc: 0.7440\n",
      "Epoch 89/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7889 - acc: 0.7519 - val_loss: 0.9226 - val_acc: 0.7435\n",
      "Epoch 90/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7821 - acc: 0.7587 - val_loss: 0.8800 - val_acc: 0.7480\n",
      "Epoch 91/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7973 - acc: 0.7501 - val_loss: 0.8902 - val_acc: 0.7439\n",
      "Epoch 92/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7830 - acc: 0.7537 - val_loss: 0.9001 - val_acc: 0.7453\n",
      "Epoch 93/100\n",
      "24269/24269 [==============================] - 230s - loss: 0.7848 - acc: 0.7536 - val_loss: 0.8885 - val_acc: 0.7490\n",
      "Epoch 94/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7858 - acc: 0.7545 - val_loss: 0.8957 - val_acc: 0.7486\n",
      "Epoch 95/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7851 - acc: 0.7550 - val_loss: 0.9254 - val_acc: 0.7406\n",
      "Epoch 96/100\n",
      "24269/24269 [==============================] - 228s - loss: 0.7861 - acc: 0.7535 - val_loss: 0.8901 - val_acc: 0.7495\n",
      "Epoch 97/100\n",
      "24269/24269 [==============================] - 231s - loss: 0.7885 - acc: 0.7544 - val_loss: 0.9008 - val_acc: 0.7447\n",
      "Epoch 98/100\n",
      "24269/24269 [==============================] - 231s - loss: 0.7842 - acc: 0.7569 - val_loss: 0.8629 - val_acc: 0.7518\n",
      "Epoch 99/100\n",
      "24269/24269 [==============================] - 231s - loss: 0.7791 - acc: 0.7557 - val_loss: 0.9063 - val_acc: 0.7477\n",
      "Epoch 100/100\n",
      "24269/24269 [==============================] - 229s - loss: 0.7819 - acc: 0.7581 - val_loss: 0.9261 - val_acc: 0.7439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb960fc4710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_epochs = 100\n",
    "model.optimizer.lr = .000001\n",
    "\n",
    "model.load_weights(os.path.join(result_path,'final_weights_210epochs.hf5'))\n",
    "model.fit_generator(batches,\n",
    "                samples_per_epoch=batches.nb_sample,\n",
    "                validation_data=val_batches,\n",
    "                nb_val_samples=val_batches.nb_sample,\n",
    "                nb_epoch=no_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "model.save_weights(os.path.join(result_path,'final_weights_310epochs.hf5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 130400 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = image.ImageDataGenerator().flow_from_directory(test_path,\n",
    "                                                             target_size=(48,48),\n",
    "                                                             class_mode='categorical',\n",
    "                                                             color_mode='grayscale',\n",
    "                                                             shuffle=False,\n",
    "                                                             batch_size=batch_size)\n",
    "\n",
    "model.load_weights(os.path.join(result_path,'final_weights_310epochs.hf5'))\n",
    "preds = model.predict_generator(test_batches, test_batches.nb_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n",
      "(130400, 121)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['1.jpg', '1.11927320177e-05', '1.69221993189e-12', '1.67455866062e-07', '2.5532399377e-06',\n",
       "       '3.67453935723e-07', '0.000899883802049', '0.00030377987423', '0.000209333928069',\n",
       "       '0.00170310190879', '1.52098629915e-13', '0.000106084356958', '0.0018167673843',\n",
       "       '0.000120061762573', '1.62218293553e-06', '1.0717430996e-05', '6.69723476676e-06',\n",
       "       '1.68615414964e-07', '7.36322181183e-06', '4.63979773713e-07', '5.69406938666e-06',\n",
       "       '6.57979171592e-06', '1.14658313066e-07', '1.46009128343e-07', '4.34908198343e-09',\n",
       "       '6.18126941845e-05', '7.13295003152e-06', '8.95665380085e-06', '0.000146111735376',\n",
       "       '1.42830538152e-06', '3.3244871247e-06', '2.34814501709e-06', '2.8121508594e-11',\n",
       "       '9.34020044951e-06', '0.000768653932028', '0.0164761170745', '0.0242573413998',\n",
       "       '0.0630942136049', '0.331187844276', '2.76640328423e-08', '9.00033483049e-05',\n",
       "       '4.79042849832e-09', '2.73407447793e-08', '1.49117404362e-05', '5.08299035573e-06',\n",
       "       '2.02384558179e-06', '1.9575516555e-11', '2.75089996925e-17', '2.63787092081e-06',\n",
       "       '1.5850064301e-05', '0.507348239422', '6.14435531534e-14', '9.80443548571e-09',\n",
       "       '1.10023665911e-06', '1.30036653445e-06', '5.97937560087e-06', '2.9878051464e-06',\n",
       "       '6.66409150085e-10', '1.26350084884e-06', '5.32790842556e-08', '7.34702165772e-09',\n",
       "       '1.38437155783e-06', '1.4331598408e-10', '3.94707289075e-09', '4.53550086377e-10',\n",
       "       '4.17439077864e-05', '8.27002804726e-06', '4.69236383083e-09', '3.46972797161e-06',\n",
       "       '5.38196161415e-07', '1.2868167687e-05', '3.59800219485e-06', '1.32515310725e-06',\n",
       "       '6.1434957388e-06', '2.35621058664e-07', '1.47119134652e-08', '6.97461954857e-09',\n",
       "       '2.65950521154e-12', '1.57645445142e-05', '2.70870148533e-09', '2.98217166517e-08',\n",
       "       '1.91498475033e-05', '9.49549357756e-05', '3.70785278392e-06', '2.78366110251e-06',\n",
       "       '9.1249930847e-06', '0.000276167062111', '3.87205727748e-06', '2.15854493035e-06',\n",
       "       '1.17207840655e-10', '9.62637045632e-07', '0.00125257158652', '4.51655942015e-05',\n",
       "       '1.4200075384e-05', '2.56318543279e-07', '3.39235293723e-06', '2.21849550144e-05',\n",
       "       '4.16794046032e-06', '1.12871498459e-06', '6.42138502371e-06', '2.91220908366e-06',\n",
       "       '1.41782152241e-06', '6.43834027869e-06', '1.99741134566e-06', '3.96752009024e-09',\n",
       "       '3.57147018804e-06', '1.14872726442e-07', '4.35694119005e-07', '1.19470664472e-08',\n",
       "       '0.000545146176592', '1.46042964388e-07', '4.47849924967e-06', '0.00389192136936',\n",
       "       '8.58344173515e-10', '4.30298750871e-05', '2.42023888859e-05', '3.29010589439e-07',\n",
       "       '6.06504329426e-07', '4.05621358368e-06', '0.00319515750743', '0.0415116921067',\n",
       "       '0.000175573353772'],\n",
       "      dtype='|S32')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.array([os.path.split(f)[-1] for f in test_batches.filenames])\n",
    "ids = np.expand_dims(ids, axis=1)\n",
    "print(preds.shape)\n",
    "subm = np.hstack([ids,preds])\n",
    "subm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image,echinoderm_larva_seastar_bipinnaria,unknown_sticks,tornaria_acorn_worm_larvae,echinoderm_seacucumber_auricularia_larva,ctenophore_lobate,pteropod_triangle,ctenophore_cestid,appendicularian_slight_curve,detritus_blob,chaetognath_non_sagitta,siphonophore_physonect_young,copepod_calanoid_octomoms,shrimp_caridean,hydromedusae_typeE,hydromedusae_typeD,hydromedusae_narco_young,siphonophore_calycophoran_rocketship_young,hydromedusae_haliscera_small_sideview,chaetognath_sagitta,hydromedusae_narco_dark,shrimp_zoea,ctenophore_cydippid_tentacles,hydromedusae_h15,acantharia_protist_halo,copepod_other,copepod_calanoid_large_side_antennatucked,copepod_calanoid_eggs,copepod_calanoid_eucalanus,copepod_calanoid_flatheads,chordate_type1,hydromedusae_solmundella,heteropod,hydromedusae_aglaura,radiolarian_colony,stomatopod,trichodesmium_multiple,copepod_cyclopoid_oithona,pteropod_butterfly,fish_larvae_leptocephali,tunicate_salp_chains,protist_other,detritus_other,echinoderm_larva_pluteus_urchin,radiolarian_chain,unknown_blobs_and_smudges,crustacean_other,invertebrate_larvae_other_B,tunicate_salp,fecal_pellet,siphonophore_other_parts,echinoderm_larva_pluteus_brittlestar,tunicate_doliolid,trochophore_larvae,acantharia_protist,hydromedusae_shapeB,hydromedusae_shapeA,fish_larvae_thin_body,hydromedusae_solmaris,protist_dark_center,ephyra,copepod_calanoid_large,fish_larvae_myctophids,amphipods,siphonophore_calycophoran_sphaeronectes_young,siphonophore_calycophoran_sphaeronectes,hydromedusae_partial_dark,trichodesmium_tuft,pteropod_theco_dev_seq,hydromedusae_sideview_big,appendicularian_fritillaridae,hydromedusae_haliscera,appendicularian_straight,hydromedusae_narcomedusae,shrimp-like_other,siphonophore_partial,fish_larvae_very_thin_body,hydromedusae_other,artifacts,echinopluteus,protist_star,echinoderm_larva_seastar_brachiolaria,trichodesmium_bowtie,hydromedusae_typeF,echinoderm_larva_pluteus_early,copepod_calanoid_small_longantennae,unknown_unclassified,artifacts_edge,detritus_filamentous,trichodesmium_puff,copepod_calanoid,hydromedusae_shapeA_sideview_small,siphonophore_calycophoran_abylidae,fish_larvae_deep_body,hydromedusae_liriope,siphonophore_calycophoran_rocketship_adult,siphonophore_physonect,appendicularian_s_shape,siphonophore_calycophoran_sphaeronectes_stem,echinoderm_larva_pluteus_typeC,copepod_calanoid_frillyAntennae,invertebrate_larvae_other_A,hydromedusae_typeD_bell_and_tentacles,jellies_tentacles,decapods,protist_fuzzy_olive,copepod_cyclopoid_oithona_eggs,shrimp_sergestidae,hydromedusae_bell_and_tentacles,fish_larvae_medium_body,chaetognath_other,euphausiids_young,ctenophore_cydippid_no_tentacles,diatom_chain_string,copepod_cyclopoid_copilia,diatom_chain_tube,euphausiids,tunicate_partial,acantharia_protist_big_center,tunicate_doliolid_nurse,polychaete,protist_noctiluca\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='plankton_subm2.csv' target='_blank'>plankton_subm2.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/fastai-notes/nbs/plankton_subm2.csv"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_filename = 'plankton_subm2.csv'\n",
    "header='image,'+','.join([str(c) for c in batches.class_indices])\n",
    "print(header)\n",
    "np.savetxt(subm_filename, subm, fmt='%s', delimiter=',', header=header, comments='')\n",
    "FileLink(subm_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_epochs = 5\n",
    "model.optimizer.lr = 0.00025\n",
    "model.load_weights(os.path.join(result_path,'weights3_epoch6.hf5'))\n",
    "for i in range(6, no_epochs+6):\n",
    "    model.fit_generator(batches,\n",
    "                    samples_per_epoch=batches.nb_sample,\n",
    "                    validation_data=val_batches,\n",
    "                    nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=1)\n",
    "    weights_filename = 'weights3_epoch{}.hf5'.format(i+1)\n",
    "    model.save_weights(os.path.join(result_path,weights_filename))\n",
    "    model.optimizer.lr *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_epochs = 30\n",
    "model.load_weights(os.path.join(result_path,'weights3_epoch5.hf5'))\n",
    "model.optimizer.lr = 0.00000001\n",
    "for i in range(10, no_epochs+10):\n",
    "    model.fit_generator(batches,\n",
    "                    samples_per_epoch=batches.nb_sample,\n",
    "                    validation_data=val_batches,\n",
    "                    nb_val_samples=val_batches.nb_sample,\n",
    "                    nb_epoch=1)\n",
    "    weights_filename = 'weights3_epoch{}.hf5'.format(i+1)\n",
    "    model.save_weights(os.path.join(result_path,weights_filename))\n",
    "    model.optimizer.lr *= 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def Maxout(x, num_unit=None):\n",
    "    # Maxout as in the paper `Maxout Networks <http://arxiv.org/abs/1302.4389>`_.\n",
    "    input_shape = x._keras_shape\n",
    "    ndim = len(input_shape)\n",
    "    assert ndim == 4 or ndim == 2\n",
    "\n",
    "    data_format = K.image_dim_ordering()\n",
    "\n",
    "    if data_format == 'th':\n",
    "        ch = input_shape[1]\n",
    "    else:\n",
    "        ch = input_shape[-1]\n",
    "\n",
    "    if num_unit == None:\n",
    "        num_unit = ch / 2\n",
    "    assert ch is not None and ch % num_unit == 0\n",
    "\n",
    "    if ndim == 4:\n",
    "        if data_format == 'th':\n",
    "            x = K.permute_dimensions(x, (0, 2, 3, 1))\n",
    "        x = K.reshape(x, (-1, input_shape[2], input_shape[3], ch / num_unit, num_unit))\n",
    "        x = K.max(x, axis=3)\n",
    "        if data_format == 'th':\n",
    "            x = K.permute_dimensions(x, (0, 3, 1, 2))\n",
    "    else:\n",
    "        print('1.')\n",
    "        x = K.reshape(x, (-1, ch / num_unit, num_unit))\n",
    "        print('2.')\n",
    "        x = K.max(x, axis=1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Old model (doesn't work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    BatchNormalization(axis=1, input_shape=(1,224,224)), # automatically normalize inputs\n",
    "    Convolution2D(32,3,3, border_mode='same', init='he_uniform'), # convolution layers\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(32,1,1, border_mode='same', init='he_uniform'), # depthwise seperate?\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(16,3,3, border_mode='same', init='he_uniform'),\n",
    "    MaxPooling2D((4,4)), # max pooling\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    Dropout(0.2),\n",
    "    Convolution2D(64,3,3, border_mode='same', init='he_uniform'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(128,3,3, border_mode='same', init='he_uniform'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(128,1,1, border_mode='same', init='he_uniform'), # depthwise seperate?\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(64,3,3, border_mode='same', init='he_uniform'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, init='he_uniform'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, init='he_uniform'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(121, activation='softmax', init='he_uniform')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
