{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.amazonaws.com/pokemontcg/xy7/54.png\" alt=\"Bulbasaur Pic\" style=\"width: 256px;\"/>\n",
    "\n",
    "# Pokemon TCG card generator\n",
    "\n",
    "- Downloads and saves card data from pokemontcg.io with python sdk, reformats it as YAML\n",
    "    - Actually, just use api directly because python sdk is out of date and parts are not compatible with each other\n",
    "- Uses keras lstm example to generate card data\n",
    "\n",
    "## Load card data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import yaml, json, os, random, requests\n",
    "from pprint import pprint\n",
    "\n",
    "data_dir = '/home/ubuntu/fastai-data/pokemon'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# query pokemontcg api for every card\n",
    "cards_full = []\n",
    "for i in range(10):\n",
    "    response = requests.get('https://api.pokemontcg.io/v1/cards?page={}&pageSize=1000'.format(i+1))\n",
    "    current_cards = json.loads(response.content)['cards']\n",
    "    cards.extend(current_cards)\n",
    "    if len(current_cards) < 1000:\n",
    "        print('-- Cards Loaded ---')\n",
    "        break\n",
    "pprint(cards_full[-1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# get card data from pokemontcg.io\n",
    "keys = ['name', 'subtype', 'supertype', 'ability', 'ancient_trait', 'hp', 'evolvesFrom',\n",
    "        'retreat_cost', 'types', 'attacks', 'weaknesses', 'resistances', 'text']\n",
    "cards = [{key: card[key] if key in card else None for key in keys} for card in cards_full]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# save data\n",
    "with open(os.path.join(data_dir,'cards.json'), 'w+') as f:\n",
    "     json.dump(cards, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    " - Convert json data to a text representation easy for a character-embedding based model to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(os.path.join(data_dir,'cards.json')) as f:\n",
    "     cards = json.load(f)\n",
    "#pprint(cards[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augment data\n",
    "for i in range(3):\n",
    "    cards.extend(random.sample(cards, len(cards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode card categories as greek letters\n",
    "alphabet = 'θωερτψυιοπασφγηςκλζχξωβνμ'\n",
    "# encode type as a unicode character, following https://redd.it/4xvh2q\n",
    "type_char = '✴☽☽⛩❤✊♨☘☘⚡⛓⚛☔'\n",
    "\n",
    "types = json.loads(requests.get('https://api.pokemontcg.io/v1/types').content)['types']\n",
    "types.insert(2, 'Dark')\n",
    "types.insert(7, 'Green')\n",
    "subtypes = json.loads(requests.get('https://api.pokemontcg.io/v1/subtypes').content)['subtypes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode type as unicode character\n",
    "def type_to_char(t_list):\n",
    "    if t_list and t_list[0] != 'Free':\n",
    "        return ''.join([type_char[types.index(t)] for t in t_list])\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# convert list of lines to single text, and replaces name with @\n",
    "def singlify(text, name=None):\n",
    "    if text:\n",
    "        text = ''.join(text) if isinstance(text, list) else text\n",
    "        if name:\n",
    "            text = text.replace(name, '@')\n",
    "        return text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# write data as txt file\n",
    "with open(os.path.join(data_dir,'cards.txt'), 'w+') as f:\n",
    "    for card in cards:\n",
    "        lines = ['\\n']\n",
    "        lines.append('|'.join([card['supertype'][0],\n",
    "                alphabet[subtypes.index(card['subtype'])] if card['subtype'] else '',\n",
    "                type_to_char(card['types']),\n",
    "                type_char[types.index(card['weaknesses'][0]['type'])] \\\n",
    "                    + ('^'*int(card['weaknesses'][0]['value'][1]) if '0' in card['weaknesses'][0]['value'] else 'x')\\\n",
    "                    if card['weaknesses'] else '',     \n",
    "                type_char[types.index(card['resistances'][0]['type'])] \\\n",
    "                    + ('^'*int(card['resistances'][0]['value'][1]) if '0' in card['resistances'][0]['value'] else 'x')\\\n",
    "                    if card['resistances'] else '',     \n",
    "                '^'*(int(card['hp'])//10) if card['hp'] and card['hp'].isdigit() else '',\n",
    "                type_to_char(card['retreat_cost']),\n",
    "                singlify(card['name']), singlify(card['evolvesFrom']), singlify(card['text'],name=card['name'])]))\n",
    "        if card['ability']:\n",
    "            lines.append(\n",
    "                '|'.join(['x', card['ability']['name'],\n",
    "                          singlify(card['ability']['text'], name=card['name'])]))\n",
    "        if card['ancient_trait']:\n",
    "            lines.append(\n",
    "                '|'.join(['y', card['ancient_trait']['name'],\n",
    "                          singlify(card['ancient_trait']['text'], name=card['name'])]))\n",
    "        if card['attacks'] and card['attacks']:\n",
    "            for attack in card['attacks']:\n",
    "                lines.append(\n",
    "                    '|'.join(['z', type_to_char(attack['cost']) if 'cost' in attack else '',\n",
    "                              str(attack['damage']), singlify(attack['name']),\n",
    "                              singlify(attack['text'], name=card['name'])]))\n",
    "        if 'マ' not in ''.join(lines): # no japanese cards\n",
    "            for line in lines:\n",
    "                f.write(line+'\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Turn text into embedded sequences that keras can use\n",
    " - Setup model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN Mixed dnn version. The header is from one version, but we link with a different version (6021, 5103))\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 17472744\n",
      "\n",
      "\n",
      "P|φ|☘|♨x||^^^^^^||Shroomish||\n",
      "z|✴||Spore|Your opponent's Active Pokémon is now Asleep.\n",
      "\n",
      "\n",
      "P|π|☘|♨x||^^^^^^^^^^||Breloom|Shroomi\n"
     ]
    }
   ],
   "source": [
    "# load text\n",
    "path = os.path.join(data_dir,'cards.txt')\n",
    "text = open(path).read()[:]\n",
    "\n",
    "print('corpus length:', len(text))\n",
    "print(text[:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 131\n",
      "\n",
      " !\"#&'()*+,-./0123456789:;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_abcdefghijklmnopqrstuvwxyz{|}~ ×éαβγδεηθικοπρςστυφψωݎ—’•↓−☔☘☽♀♂♨⚛⚡⛓⛩✊✴❤＋\n"
     ]
    }
   ],
   "source": [
    "# get characters used in text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print('total chars:', vocab_size)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create character indices\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "# turn text into char indices\n",
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 128\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(len(idx)-maxlen+1):\n",
    "    sentences.append(idx[i: i + maxlen])\n",
    "    next_chars.append(idx[i+1: i+maxlen+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of sequences: 17472617\n"
     ]
    }
   ],
   "source": [
    "print('# of sequences:', len(sentences))\n",
    "\n",
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(os.path.join(data_dir,'sentences'), sentences)\n",
    "np.save(os.path.join(data_dir,'next_chars'), sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# size of embedding\n",
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen),\n",
    "        GRU(256, input_shape=(n_fac,),return_sequences=True, dropout=0.01, recurrent_dropout=0.01),\n",
    "        Dropout(0.2),\n",
    "        GRU(512, return_sequences=True, dropout=0.01, recurrent_dropout=0.01),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.01), metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "import random\n",
    "\n",
    "# print example text, \n",
    "def print_example(length=800, temperature=0.7, mult=2):\n",
    "    seed_len=40\n",
    "    path = os.path.join(data_dir,'cards.txt')\n",
    "    text = open(path).read()[:]\n",
    "    ind = random.randint(0,len(text)-seed_len-1)\n",
    "    seed_string = text[ind:ind+seed_len]\n",
    "    \n",
    "    for i in range(length):\n",
    "        if (seed_string.split('\\n')[-1].count('|') == 7 or\n",
    "        seed_string.startswith(('x','y')) and seed_string.split('\\n')[-1].count('|') == 1 or\n",
    "        seed_string.startswith('z') and seed_string.split('\\n')[-1].count('|') == 3):\n",
    "            temp = temperature * mult # make names more creative\n",
    "        else:\n",
    "            temp = temperature\n",
    "        \n",
    "        x=np.array([char_indices[c] for c in seed_string[-40:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = np.log(preds) / temp\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        print(next_char, end=\"\")\n",
    "        seed_string = seed_string + next_char\n",
    "    \n",
    "    #print(seed_string[seed_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LambdaCallback\n",
    "import h5py\n",
    "\n",
    "def print_callback(logs, epoch):\n",
    "    print_example()\n",
    "\n",
    "result_dir = os.path.join(data_dir, 'results')\n",
    "weight_path = \"weights-{epoch:02d}-{acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(os.path.join(result_dir, weight_path),\n",
    "                             monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.00000001)\n",
    "printer = LambdaCallback(on_epoch_end=print_callback)\n",
    "\n",
    "callbacks_list = [printer, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "history = model.fit(sentences,\n",
    "                    np.expand_dims(next_chars,-1),\n",
    "                    batch_size=256,\n",
    "                    epochs=num_epochs,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture generated_cards\n",
    "print_example(length=300000, temperature=0.7, mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir,'cards_generated.txt'), 'w+') as f:\n",
    "    f.write(generated_cards.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Output\n",
    "\n",
    " - At this point I redid the prior stuff with a premade tensorflow char-rnn model, to see if it was any better. I didn't feel as if there were significant improvements but it did run considerably faster.\n",
    " - Decode generated text back into JSON format\n",
    " - Convert JSON format to card images"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Run in terminal, in tensorflow-char-rnn directory, with python 3.6:\n",
    "\n",
    "python train.py --data_file=/home/ubuntu/fastai-data/pokemon/cards.txt --output_dir=/home/ubuntu/fastai-data/pokemon/results_tf --embedding_size=30 --model=lstm --hidden_size=256 --num_layers=3 --batch_size=96 --learning_rate=0.001 --num_epochs=120\n",
    "\n",
    "and in a seperate tmux pane:\n",
    "\n",
    "tensorboard --logdir=/home/ubuntu/fastai-data/pokemon/results_tf/tensorboard_log --port=6006\n",
    "\n",
    "Afterwards, run:\n",
    "\n",
    "python sample.py --init_dir=/home/ubuntu/fastai-data/pokemon/results_tf --start_text=\"P|j|R|g|fx||^^^^^^^^^^|cc|Breloom|\" --length=500000 --seed=4745 --temperature=0.7 | tee /home/ubuntu/fastai-data/pokemon/cards_generated_tf2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode card categories as greek letters\n",
    "alphabet = 'θωερτψυιοπασφγηςκλζχξωβνμ'\n",
    "# encode type as a unicode character, following https://redd.it/4xvh2q\n",
    "type_char = '✴☽⛩❤✊♨☘⚡⛓⚛☔'\n",
    "\n",
    "types = json.loads(requests.get('https://api.pokemontcg.io/v1/types').content)['types']\n",
    "subtypes = json.loads(requests.get('https://api.pokemontcg.io/v1/subtypes').content)['subtypes']\n",
    "supertypes = json.loads(requests.get('https://api.pokemontcg.io/v1/supertypes').content)['supertypes']\n",
    "with open(os.path.join(data_dir,'cards.json')) as f:\n",
    "     old_names = [card['name'] for card in json.load(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decode type from unicode character\n",
    "def char_to_type(chars):\n",
    "    if chars and len(chars) > 0:\n",
    "        return [types[type_char.index(char)] for char in chars]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "cards = []\n",
    "card = None\n",
    "with open(os.path.join(data_dir,'cards_generated.txt')) as f:\n",
    "    for line in f:\n",
    "        line = line.split('|')\n",
    "        if line[0] in ('P','E','T'):\n",
    "            if card and card['name'].rstrip() not in old_names:\n",
    "                cards.append(card)\n",
    "            try:\n",
    "                card = {'supertype': supertypes[('P','E','T').index(line[0])],\n",
    "                        'subtype': subtypes[alphabet.index(line[1])] if line[1] else None,\n",
    "                        'types': char_to_type(line[2]),\n",
    "                        'weaknesses':\n",
    "                        {'type': types[type_char.index(line[3][0])],\n",
    "                         'value': '×2' if line[4][1] == 'x' else '-'+str(len(line[4])-1)+'0'} if line[4] else None,\n",
    "                        'resistances':\n",
    "                        {'type': types[type_char.index(line[4][0])],\n",
    "                         'value': '×2' if line[5][1] == 'x' else '-'+str(len(line[5])-1)+'0'} if line[5] else None,\n",
    "                        'hp': len(line[5])*10 if line[6] else None,\n",
    "                        'retreat_cost': char_to_type(line[6]),\n",
    "                        'name': line[7].rstrip(),\n",
    "                        'evolvesFrom': line[8].rstrip(),\n",
    "                        'text': line[9].replace('@',line[8]).rstrip() if len(line) > 9 else None}\n",
    "            except:\n",
    "                card = None\n",
    "                print('Skipped card')\n",
    "        elif line[0] == 'x' and card and card['supertype'] == 'Pokémon':\n",
    "            try:\n",
    "                card['ability'] = {'name':line[1].rstrip(),\n",
    "                                   'text':line[2].replace('@',card['name']).rstrip() if len(line) > 2 else None}\n",
    "            except:\n",
    "                print('Skipped ability')\n",
    "        elif line[0] == 'y' and card and card['supertype'] == 'Pokémon':\n",
    "            try:\n",
    "                card['ancient_trait'] = {'name':line[1].rstrip(),\n",
    "                                         'text':line[2].replace('@',card['name']).rstrip() if len(line) > 2 else None}\n",
    "            except:\n",
    "                print('Skipped trait')\n",
    "        elif line[0] == 'z' and card and card['supertype'] == 'Pokémon':\n",
    "            try:\n",
    "                card.setdefault('attacks', []).append(\n",
    "                    {'cost': char_to_type(line[1]),\n",
    "                     'damage': line[2],\n",
    "                     'name': line[3].rstrip(),\n",
    "                     'text': line[4].replace('@',card['name']).rstrip() if len(line) > 4 else None})\n",
    "            except:\n",
    "                print('Skipped attack')\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExplicitDumper(yaml.SafeDumper):\n",
    "    def ignore_aliases(self, data):\n",
    "        return True\n",
    "    \n",
    "with open('cards_generated.yml', 'w+') as f:\n",
    "     yaml.dump(cards, f, allow_unicode=True, Dumper=ExplicitDumper, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('cards_generated.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Card Mockups\n",
    "\n",
    "- Using Paulsnoop's BWXY card templates and symbol sheet (from deviantart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os, textwrap\n",
    "\n",
    "data_dir = '/home/ubuntu/fastai-data/pokemon_img'\n",
    "template_path = os.path.join(data_dir, 'templates')\n",
    "save_path = os.path.join(data_dir, 'card_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml, pprint, re, unidecode\n",
    "\n",
    "card_data = []\n",
    "with open('cards_generated.yml') as f:\n",
    "     card_data = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only supports basic pokemon for now\n",
    "def get_energy_img(energy, category):\n",
    "    energies = ['Grass', 'Fire', 'Water', 'Electric', 'Psychic', 'Fighting',\n",
    "                'Dark', 'Metal', 'Fairy', 'Dragon', 'Colorless']\n",
    "    full_img = Image.open('symbols.png')\n",
    "    if category is 'attack':\n",
    "        img = full_img.crop((46+energies.index(energy)*57, 85, 85+energies.index(energy)*57, 135))\n",
    "    if category is 'weakness':\n",
    "        img = full_img.crop((50+energies.index(energy)*57, 210, 80+energies.index(energy)*57, 250))\n",
    "    return img\n",
    "\n",
    "def gen_card_img(card):\n",
    "    if card['supertype'] == 'Pokémon':\n",
    "        img = Image.open(os.path.join(template_path,\n",
    "                         card['supertype'], 'Basic',\n",
    "                         card['types'][0]+'.png'))\n",
    "        \n",
    "        d = ImageDraw.Draw(img)\n",
    "        \n",
    "        f = ImageFont.truetype(font='fonts/gill-rb.ttf', size=48)\n",
    "        d.text((180,36), card['name'], font=f, fill='black')\n",
    "\n",
    "        f = ImageFont.truetype(font='fonts/gill-rb.ttf', size=18)\n",
    "        d.text((556, 68), 'HP', font=f, fill='black')\n",
    "\n",
    "        f = ImageFont.truetype(font='fonts/futura-cb.ttf', size=44)\n",
    "        d.text((582, 42), str(card['hp']), font=f, fill='black')\n",
    "        \n",
    "        f = ImageFont.truetype(font='fonts/futura-cb.ttf', size=30)\n",
    "        if card['weaknesses']:\n",
    "            energy_img = get_energy_img(card['weaknesses']['type'], 'weakness')\n",
    "            img.paste(energy_img, (65, 888), energy_img)\n",
    "            d.text((100, 890), card['weaknesses']['value'], font=f, fill='black')\n",
    "        if card['resistances']:\n",
    "            energy_img = get_energy_img(card['resistances']['type'], 'weakness')\n",
    "            img.paste(energy_img, (195, 888), energy_img)\n",
    "            d.text((230, 890), card['resistances']['value'], font=f, fill='black')\n",
    "        \n",
    "        full_img = Image.open('symbols.png')\n",
    "        retreat_img = full_img.crop((517, 433, 517+32*len(card['retreat_cost']),463))\n",
    "        img.paste(retreat_img, (150, 938), retreat_img)\n",
    "\n",
    "        start_height = 560\n",
    "        if 'ability' in card:\n",
    "            ability = card['ability']\n",
    "            \n",
    "            ability_img = full_img.crop((50, 433, 212, 475))\n",
    "            img.paste(ability_img, (60, start_height+5), ability_img)\n",
    "            \n",
    "            f = ImageFont.truetype(font='fonts/gill-cb.ttf', size=44)\n",
    "            d.text((240, start_height), ability['name'], font=f, fill='#c23600')\n",
    "            \n",
    "            f = ImageFont.truetype(font='fonts/gill-rp.ttf', size=30)\n",
    "            d.multiline_text((60, start_height+54), textwrap.fill(ability['text'], width=48), font=f, fill='black')\n",
    "            \n",
    "            start_height += 80 + d.multiline_textsize(textwrap.fill(ability['text'], width=48), font=f)[1]\n",
    "        if 'attacks' in card:\n",
    "            for attack in card['attacks']:\n",
    "                if start_height >= 760:\n",
    "                    break\n",
    "                \n",
    "                for n in range(len(attack['cost'])):\n",
    "                    energy_img = get_energy_img(attack['cost'][n],'attack')\n",
    "                    img.paste(energy_img, (60+n*45, start_height), energy_img)\n",
    "                \n",
    "                f = ImageFont.truetype(font='fonts/gill-cb.ttf', size=44)\n",
    "                d.text((115+n*45, start_height), attack['name'], font=f, fill='black')\n",
    "\n",
    "                f = ImageFont.truetype(font='fonts/futura-cb.ttf', size=44)\n",
    "                d.text((612, start_height), attack['damage'], font=f, fill='black')\n",
    "\n",
    "                f = ImageFont.truetype(font='fonts/gill-rp.ttf', size=30)\n",
    "                d.multiline_text((60, start_height+54), textwrap.fill(attack['text'], width=48), font=f, fill='black')\n",
    "\n",
    "                start_height += 80 + d.multiline_textsize(textwrap.fill(attack['text'], width=48), font=f)[1]\n",
    "        \n",
    "    elif card['supertype'] == 'Trainer':\n",
    "        img = Image.open(os.path.join(template_path,\n",
    "            card['supertype'], (card['subtype'].replace(' ','_') if card['subtype'] else 'Supporter')+'.png'))\n",
    "        d = ImageDraw.Draw(img)\n",
    "        \n",
    "        f = ImageFont.truetype(font='fonts/gill-rb.ttf', size=44)\n",
    "        d.text((85,105), card['name'], font=f, fill='black')\n",
    "        \n",
    "        f = ImageFont.truetype(font='fonts/gill-rp.ttf', size=30)\n",
    "        d.multiline_text((95, 570), textwrap.fill(card['text'] if card['text'] else '', width=42), font=f,fill='black')\n",
    "    else:\n",
    "        img = Image.open(os.path.join(template_path,\n",
    "            card['supertype'], (card['subtype'].replace(' ','_') if card['subtype'] else 'Supporter')+'.png'))\n",
    "        d = ImageDraw.Draw(img)\n",
    "        \n",
    "        f = ImageFont.truetype(font='fonts/gill-rb.ttf', size=30)\n",
    "        d.text((80,100), 'Special Energy', font=f, fill='black')\n",
    "        \n",
    "        f = ImageFont.truetype(font='fonts/gill-rb.ttf', size=40)\n",
    "        d.text((60,655), card['name'], font=f, fill='black')\n",
    "        \n",
    "        f = ImageFont.truetype(font='fonts/gill-rp.ttf', size=30)\n",
    "        d.multiline_text((60, 720), textwrap.fill(card['text'], width=48), font=f, fill='black')\n",
    "    \n",
    "    background = Image.open('holosheet.jpg')\n",
    "    background.paste(img, (0, 0), img)\n",
    "    img = background\n",
    "\n",
    "    img.thumbnail((512,512))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turns string into filename\n",
    "def slugify(value):\n",
    "    value = unidecode.unidecode(value)\n",
    "    value = str(re.sub('[^\\w\\s-]', '', value).strip())\n",
    "    value = str(re.sub('[-\\s]+', '-', value))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for card in card_data:\n",
    "    try:\n",
    "        print(card['name'])\n",
    "        img = gen_card_img(card)\n",
    "        img.save(os.path.join(save_path, slugify(card['name'])+'.jpg'))\n",
    "    except:\n",
    "        print('skipped a card')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "card_names = ['Auror', 'Mr. Show the top card.', 'Scorched Seal', 'Bubble']\n",
    "\n",
    "card = None\n",
    "for name in card_names:\n",
    "    card = next((c for c in card_data if c['name'] == name), None)\n",
    "    if card:\n",
    "        #pprint.pprint(card)\n",
    "        gen_card_img(card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"https://cdn.bulbagarden.net/upload/2/21/001Bulbasaur.png\" alt=\"Bulbasaur Pic\" style=\"width: 256px;\"/>\n",
    "\n",
    "# Generate Card Images\n",
    "\n",
    "1. Download Ken Sugimori art from [bulbapedia](https://archives.bulbagarden.net/wiki/Category:Ken_Sugimori_Pok%C3%A9mon_artwork), augment\n",
    "2. Use [DRAGAN](https://github.com/kodalinaveen3/DRAGAN) to generate new pokemon art\n",
    "3. Use PIL to combine random char-rnn generated card properties and DRAGAN generated art, using [templates](https://pokemoncardresources.deviantart.com/gallery/51274687/Resources-Classic)\n",
    "\n",
    "## Download from Bulbapedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_name = 'Ken_Sugimori_Pokémon_artwork'\n",
    "data_dir = '/home/ubuntu/fastai-data/pokemon_img'\n",
    "png_path = os.path.join(data_dir, 'pngs')\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mwclient, requests, shutil\n",
    "\n",
    "site = mwclient.Site('archives.bulbagarden.net')\n",
    "category = site.Categories[cat_name]\n",
    "filenames = (x.page_title for x in category.members(namespace=6))\n",
    "for file in filenames:\n",
    "    file_url = 'http://archives.bulbagarden.net/w/index.php?title=Special:FilePath&file={}&width={}'.format(\n",
    "            file, img_width)\n",
    "    r = requests.get(file_url, stream=True)\n",
    "    if not r.status_code == 200:\n",
    "        print('Requested width is bigger than source - downloading full size')\n",
    "        file_url = 'http://archives.bulbagarden.net/w/index.php?title=Special:FilePath&file={}'.format(file)\n",
    "        r = requests.get(file_url, stream=True)\n",
    "    print('Thumbnail found')\n",
    "    if r.status_code == 200:\n",
    "        print('Saving file '+file)\n",
    "        output_filepath = os.path.join(png_path, file.replace(' ','_'))\n",
    "        with open(output_filepath, 'wb+') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GAN\n",
    "\n",
    "- Basically copied [makegirlsmoe](https://makegirlsmoe.github.io/assets/pdf/technical_report.pdf)'s architecture and [pytorch DRAGAN](https://github.com/jfsantos/dragan-pytorch/blob/master/dragan.py) / [keras WGAN-GP](https://github.com/farizrahman4u/keras-contrib/blob/master/examples/improved_wgan.py)'s code, because I don't know what I'm doing that well.\n",
    "- GANs (Generative Adverserial Networks) use a competition between a generator and discriminator neural network to gradually make the generator output match existing samples\n",
    "    - GANs are inefficient in pure keras - probably good to learn pytorch sometime\n",
    "    - also don't combine learning a new generator architecture (resnet), a new concept (GANs), and an experimental GAN architecture (DRAGAN) at the same time next time. Especially do not do this all while using the entire data set for training rather than samples.\n",
    "    - Every batch, first train the discriminator network to correctly classify real and generated images\n",
    "        - discriminator is a convolutional image classifier network that classifies images as real or fake (binary).\n",
    "        - discriminator network is actually stacked generator and discriminator, but only discriminator weights are being trained. Input a batch of real images and a batch of noise, feed the noise through the generator and then through the discriminator (real images go straight to discriminator), and optimize discriminator to classify real images as real and generated images as fake.\n",
    "    - then, train the generator network to fool the discriminator network\n",
    "        - generator takes noise vector and generates image. In this case we reshape a noise vector into an image, use a dense layer to increase a low resolution image's depth (# of channels), convolutional layers to create features, and pixel shuffles to increase resolution by decreasing depth, until we end up with an appropriate image.\n",
    "        - generator network is also stacked generator and discriminator, but only the generator weights are trained now. Input a batch of noise, feed it through the generator and discriminator, and optimize the generator so the discriminator classifies the generated images as real (by feeding it the opposite labels).\n",
    "    - Overall discriminator loss should be lower than generator loss (so generator always has a somewhat accurate goal);  about 0.1-1 discriminator loss and 2-7 generator loss may be good. Loss should not converge but reach equilibrium, as increasing discriminator accuracy leads to better generator which lowers discriminator accuracy and vice versa.\n",
    "    - DRAGAN adds a gradient penalty to the discriminator to make it easier to train. Creates perturbed images (adding noise vectors to real images) and adds a penalty to the loss function proportional to the gradient of the discriminator at those perturbed images (should make discriminator more linear?)\n",
    "    - GAN tricks is very helpful, and follow pytorch DRAGAN implementation as closely as possible\n",
    "        - Remember example implementations and overview papers often don't show things like dropout\n",
    "- Resnets use skip connections to make networks more linear and help with deep networks\n",
    "    - resblocks have skip connections, where output from earlier layer is elementwise summed with output from later layer. See resnet paper. This helps make deep networks more linear and generalizable\n",
    "    - pixel shuffle is used to increase resolution, by making an image tensor wider (higher res) but shallower (fewer channels). See [subpixel](https://github.com/tetrachrome/subpixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import theano\n",
    "\n",
    "#theano.config.optimizer_including='alloc_empty_to_zeros'\n",
    "#theano.config.nvcc.fastmath = False\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import theano.tensor as T\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.initializers import *\n",
    "from keras.layers import *\n",
    "from keras.engine.topology import Layer\n",
    "from keras.optimizers import Adam\n",
    "import itertools, os\n",
    "import numpy as np\n",
    "\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defines some layer functions for use in generator and discriminator networks\n",
    "- pixel shuffle from https://github.com/titu1994/Super-Resolution-using-Generative-Adversarial-Networks/blob/master/models.py\n",
    "- Appears that changing to upscale + convolution instead of deconvolution (convolution + pixel shuffle) improves diversity of results as well as eliminates checkerboard artifacts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pixel_shuffle(input, scale, channels):\n",
    "    b, k, row, col = input.shape\n",
    "    output_shape = (b, channels, row * scale, col * scale)\n",
    "    out = T.zeros(output_shape)\n",
    "    r = scale\n",
    "    for y, x in itertools.product(range(scale), repeat=2):\n",
    "        out = T.inc_subtensor(out[:, :, y::r, x::r], input[:, r * y + x :: r * r, :, :])\n",
    "    return out\n",
    "\n",
    "class PixelShuffle(Layer):\n",
    "    def __init__(self, r, channels, **kwargs):\n",
    "        super(PixelShuffle, self).__init__(**kwargs)\n",
    "        self.r = r\n",
    "        self.channels = channels\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(PixelShuffle, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return pixel_shuffle(x, self.r, self.channels)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        b, k, r, c = input_shape\n",
    "        return (b, self.channels, r * self.r, c * self.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# residual block for generative network\n",
    "def resblock(x):\n",
    "    skip = x\n",
    "    \n",
    "    x = Conv2D(64, 3, padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, 3, padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Add()([x, skip])\n",
    "    \n",
    "    return x\n",
    "\n",
    "# residual block for discriminator network\n",
    "def resblock2(x, filters=32, strides=1):\n",
    "    skip = x\n",
    "    \n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv2D(filters, 3, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv2D(filters, 3, padding='same', strides=strides)(x)\n",
    "    x = Add()([x, skip])\n",
    "    \n",
    "    return x\n",
    "\n",
    "# superresolution CNN\n",
    "def sp_cnn(x):\n",
    "    #x = Conv2D(256, 3, padding='same')(x)\n",
    "    #x = PixelShuffle(2, 64)(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(64, 3, padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    #x = PReLU()(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creates a super-resolution resnet like generator model, and a resnet discriminator model, approx. according to the [technical report](https://makegirlsmoe.github.io/assets/pdf/technical_report.pdf)\n",
    "- generator model has less resblocks to reduce complexity and make it not converge as fast\n",
    "- looks more random if activations are removed from sp_cnn blocks?\n",
    "- Using tanh instead of relu and family seems to make things better as well?\n",
    "- Adding gaussian noise to input of discriminator might stabilize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generator network architecture\n",
    "def get_generator(x, dim=16, depth=256):\n",
    "    x = Dense(depth*dim*dim)(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Reshape((depth, dim, dim))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    skip = x = Conv2D(64, 1, padding='same')(x)\n",
    "\n",
    "    for i in range(12):\n",
    "        x = resblock(x)\n",
    "        \n",
    "    x = Conv2D(64, 3, padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Add()([x, skip])\n",
    "    \n",
    "    for i in range(3):\n",
    "        x = sp_cnn(x)\n",
    "    \n",
    "    x = Conv2D(3, 9, padding='same')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# discriminator network architecture\n",
    "def get_discriminator(x):\n",
    "    x = GaussianNoise(0.0)(x)\n",
    "    x = Conv2D(32, 4, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    for i in range(5):\n",
    "        x = resblock2(x, filters=2**(5+i))\n",
    "        x = resblock2(x, filters=2**(5+i))\n",
    "        if (i < 2):\n",
    "            x = Conv2D(2**(6+i), 4, strides=2, padding='same')(x)\n",
    "        else:\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Conv2D(2**(6+i), 3, strides=2, padding='same')(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_input = Input(shape=[128])\n",
    "generator = Model(inputs=g_input, outputs=get_generator(g_input))\n",
    "\n",
    "test = generator.predict(np.random.normal(size=(8, 128), scale=1))\n",
    "print('max: {} min: {} mean: {}'.format(np.max(test), np.min(test), np.mean(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_input = Input(shape=[3, 128, 128])\n",
    "discriminator = Model(inputs=d_input, outputs=get_discriminator(d_input))\n",
    "\n",
    "test2 = discriminator.predict(generator.predict(np.random.normal(size=(8, 128), scale=1)))\n",
    "print('max: {} min: {} mean: {}'.format(np.max(test2), np.min(test2), np.mean(test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converts generator and discriminator networks into the form required for DRAGAN training\n",
    "    - adds nontrainable discriminator network layers to generator, to allow us to maximize discriminator loss\n",
    "    - adds other loss functions and inputs to discriminator network, so it trains on real examples as well as generated examples, and uses the DRAGAN gradient penalty\n",
    "    - generator should have lower learning rate than discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discriminator_model trains discriminator with real and generated images\n",
    "for layer in discriminator.layers:\n",
    "    layer.trainable = True\n",
    "for layer in generator.layers:\n",
    "    layer.trainable = False\n",
    "discriminator.trainable = True\n",
    "generator.trainable = False\n",
    "\n",
    "# blog article suggests perturbing in all directions (-1-1 rather than 0-1)\n",
    "def perturb(input, c=0.5):\n",
    "    b, row, col, k = input.shape\n",
    "    alpha = K.repeat_elements(K.repeat_elements(K.repeat_elements(\n",
    "        K.random_uniform((b, 1, 1, 1), 0, 1), row, 1), col, 2), k, 3)\n",
    "    x_hat = alpha*input + (1-alpha)*(input + c * K.std(input) * K.random_uniform((b, row, col, k), 0, 1))\n",
    "    return x_hat\n",
    "\n",
    "imgs = Input(shape=[3, 128, 128]) # real mini-batch\n",
    "noise = Input(shape=[128])\n",
    "p_imgs = Lambda(perturb, output_shape=K.int_shape(imgs)[1:])(imgs) # perturbed mini-batch\n",
    "\n",
    "# from keras WGAN-GP, though called with randomly perturbed inputs rather than averaged inputs\n",
    "def gradient_penalty(y_true, y_pred, x_hat=p_imgs):\n",
    "    gradients = K.gradients(K.sum(y_pred), x_hat)\n",
    "    gradient_l2_norm = K.sqrt(K.sum(K.square(gradients), axis=[1,2,3]))\n",
    "    gradient_penalty = K.mean(K.square(gradient_l2_norm - 1))\n",
    "    return gradient_penalty\n",
    "\n",
    "discriminator_model = Model(inputs=[imgs, noise],\n",
    "                            outputs=[discriminator(imgs), discriminator(generator(noise)), discriminator(p_imgs)])\n",
    "discriminator_model.compile(optimizer=Adam(0.0001),\n",
    "                            loss=['binary_crossentropy', 'binary_crossentropy', gradient_penalty],\n",
    "                            loss_weights=[0.4, 0.4, 0.2])\n",
    "\n",
    "\n",
    "#perturb_test_model = Model(inputs=imgs, outputs=p_imgs)\n",
    "#perturb_test_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "#test2 = discriminator_model.predict([generator.predict(np.random.normal(size=(4, 128))),\n",
    "#                                     np.random.normal(size=(4, 128))])\n",
    "#print('max: {} min: {} mean: {}'.format(np.max(test2[1]), np.min(test2[1]), np.mean(test2[1])))\n",
    "discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generator_model trains generator to create image, optimizes to maximize discriminator loss\n",
    "for layer in discriminator.layers:\n",
    "    layer.trainable = False\n",
    "for layer in generator.layers:\n",
    "    layer.trainable = True\n",
    "discriminator.trainable = False\n",
    "generator.trainable = True\n",
    "\n",
    "gm_input = Input(shape=[128])\n",
    "generator_model = Model(inputs=gm_input, outputs=discriminator(generator(gm_input)))\n",
    "generator_model.compile(optimizer=Adam(0.0001), loss='binary_crossentropy')\n",
    "\n",
    "#test = generator_model.predict(np.random.normal(size=(4, 256)))\n",
    "#print('max: {} min: {} mean: {}'.format(np.max(test), np.min(test), np.mean(test)))\n",
    "generator_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Your DRAGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random, os\n",
    "\n",
    "# Instantiate plotting tool\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=2, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/ubuntu/fastai-data/pokemon_img'\n",
    "train_path = os.path.join(data_dir, 'train')\n",
    "temp_path = os.path.join(data_dir, 'temp')\n",
    "result_path = os.path.join(data_dir, 'results')\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(dirname, temp_dir=None, shuffle=True, batch_size=batch_size):\n",
    "    gen = image.ImageDataGenerator(preprocessing_function=lambda x: (x - 127.5)/128,\n",
    "                                  horizontal_flip=True,\n",
    "                                  width_shift_range=0.09,\n",
    "                                  height_shift_range=0.09,\n",
    "                                  zoom_range=[1.1, 1.65],\n",
    "                                  shear_range=0.18,\n",
    "                                  fill_mode='constant',\n",
    "                                  cval=255,\n",
    "                                  channel_shift_range=8)\n",
    "    return gen.flow_from_directory(dirname,\n",
    "                                  target_size=(128,128),\n",
    "                                  class_mode='binary',\n",
    "                                  color_mode='rgb',\n",
    "                                  shuffle=shuffle,\n",
    "                                  save_to_dir=temp_dir,\n",
    "                                  batch_size=batch_size)\n",
    "\n",
    "batches = get_batches(train_path, temp_dir=temp_path)\n",
    "#batches = get_batches(train_path)\n",
    "\n",
    "for i in range(5000):\n",
    "    batch, labels = next(batches)\n",
    "print('max: {} min: {} mean: {}'.format(np.max(batch), np.min(batch), np.mean(batch)))\n",
    "plots([image.load_img(os.path.join(temp_path, img)) for img in random.sample(os.listdir(temp_path), 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def tile_images(image_stack):\n",
    "    assert len(image_stack.shape) == 4\n",
    "    image_list = [image_stack[i, :, :, :] for i in range(image_stack.shape[0])]\n",
    "    #image_list = [image_stack[i, :, :] for i in range(image_stack.shape[0])]\n",
    "    tiled_images = np.concatenate(image_list, axis=1)\n",
    "    tiled_images = np.swapaxes(tiled_images, 0, 2)\n",
    "    return tiled_images\n",
    "\n",
    "def generate_images(generator, output_dir, epoch):\n",
    "    test_image_stack = generator.predict(np.random.normal(size=(8, 128), scale=1)) \n",
    "    test_image_stack = (test_image_stack * 127.5) + 127.5\n",
    "    test_image_stack = np.squeeze(np.round(test_image_stack).astype(np.uint8))\n",
    "    tiled_output = tile_images(test_image_stack)\n",
    "    tiled_output = Image.fromarray(tiled_output, mode='RGB')\n",
    "    outfile = os.path.join(output_dir, 'epoch_{}.png'.format(epoch))\n",
    "    tiled_output.save(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import dcgan\n",
    "#generator = dcgan.generator_model()\n",
    "#generator.compile(optimizer=Adam(0.0001), loss='binary_crossentropy')\n",
    "\n",
    "test_image_stack = generator.predict(np.random.normal(size=(8, 128), scale=1))\n",
    "test_image_stack = (test_image_stack * 127.5) + 127.5\n",
    "test_image_stack = np.squeeze(np.round(test_image_stack).astype(np.uint8))\n",
    "tiled_output = tile_images(test_image_stack)\n",
    "tiled_output = Image.fromarray(tiled_output, mode='RGB')\n",
    "outfile = os.path.join(temp_path, 'perturb_test.png')\n",
    "tiled_output.save(outfile)\n",
    "\n",
    "plots([image.load_img(outfile)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Concensus from [Animeface-GAN](https://github.com/forcecore/Keras-GAN-Animeface-Character) and others seems to be generator loss of 2-4 and discriminator loss around 0.3 is good\n",
    "- One sided label noising and both sided label smoothing for discriminator, no smoothing or noising for generator seems to work well for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches_per_epoch = int(1426 / batch_size)\n",
    "\n",
    "true_positive_y = np.ones((batch_size, 1))\n",
    "true_negative_y = np.zeros((batch_size, 1))\n",
    "dummy_y = np.zeros((batch_size, 1)) + 0.5\n",
    "\n",
    "epoch = 0\n",
    "if epoch > 0:\n",
    "    generator_model.load_weights(os.path.join(result_path, 'gan_g_weights{}.h5'.format(epoch)))\n",
    "    discriminator_model.load_weights(os.path.join(result_path, 'gan_d_weights{}.h5'.format(epoch)))\n",
    "    discriminator_loss = np.loadtxt(os.path.join(result_path, 'gan_d_loss_history.csv'))\n",
    "    discriminator_loss = list(np.broadcast_to(\n",
    "        np.expand_dims(discriminator_loss, axis=1),(discriminator_loss.shape[0], 4)))\n",
    "    generator_loss =  list(np.loadtxt(os.path.join(result_path, 'gan_g_loss_history.csv')))\n",
    "    batch_num = len(discriminator_loss) + 1\n",
    "else:\n",
    "    discriminator_loss = []\n",
    "    generator_loss = []\n",
    "    batch_num = 0\n",
    "\n",
    "epoch += 1\n",
    "print('Epoch ' + str(epoch) + '\\n')\n",
    "for batch, labels in batches: # folder labels not actually used\n",
    "    \n",
    "    if batch_num % batches_per_epoch == 0 and batch_num > 0:\n",
    "        generate_images(generator, result_path, epoch)\n",
    "        if generator_loss[-1] > 0.5:\n",
    "            try:\n",
    "                generator_model.save_weights(os.path.join(result_path, 'gan_g_weights{}.h5'.format(epoch)))\n",
    "                discriminator_model.save_weights(os.path.join(result_path, 'gan_d_weights{}.h5'.format(epoch)))\n",
    "            except:\n",
    "                print('Weights could not be saved')\n",
    "        epoch += 1\n",
    "        print('\\nEpoch ' + str(epoch))\n",
    "    \n",
    "    if len(batch) == batch_size:\n",
    "        # smooth positive labels only\n",
    "        positive_y = np.random.uniform(0.7, 1.2, size=(batch_size, 1))\n",
    "        negative_y = np.zeros((batch_size, 1))+0.05\n",
    "    \n",
    "        # train discriminator with real, generated, and perturbed images\n",
    "        noise = np.random.normal(size=(batch_size, 128), scale=1)\n",
    "        discriminator_loss.append(\n",
    "            discriminator_model.train_on_batch([batch, noise],[positive_y, negative_y, dummy_y]))\n",
    "        \n",
    "        print('D. Loss | Total: ' + str(discriminator_loss[-1][0])\n",
    "              + ' | Real: ' + str(discriminator_loss[-1][1])\n",
    "              + ' | Fake: ' + str(discriminator_loss[-1][2])\n",
    "              + ' | Penalty: ' + str(discriminator_loss[-1][3]))\n",
    "        np.savetxt(os.path.join(result_path, 'gan_d_loss_history.csv'), np.asarray(discriminator_loss)[:,0])\n",
    "\n",
    "        # train generator to maximize discriminator loss\n",
    "        noise2 = np.random.normal(size=(batch_size, 128), scale=1)\n",
    "        positive_y = np.random.uniform(0.85, 1.05, size=(batch_size, 1))\n",
    "        generator_loss.append(\n",
    "            generator_model.train_on_batch(noise2, positive_y))\n",
    "            \n",
    "        print('G. Loss: '+  str(generator_loss[-1]))\n",
    "        np.savetxt(os.path.join(result_path, 'gan_g_loss_history.csv'), np.asarray(generator_loss))\n",
    "    batch_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with hypergan card images because keras is soooo slow\n",
    "\n",
    "- Seriously, raw tensorflow is like at least 10 times faster than keras for this. Also keras keeps making me tweak the hyperparameters every few epochs to avoid nans. I really should learn pytorch soon. Maybe my generator and discriminator architectures are overkill, but the double evaluation for each model and the gradient penalty are very inefficient in keras.\n",
    "\n",
    "- Looks like hypergan isn't very effective for this task either - discriminator or generator loss goes to 0 after just a few epochs, no matter what hyperparameters I try. May need more data augmentation, and it's easier to do that in keras."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Train a 256x256 gan with batch size 32 on a folder of pngs\n",
    "hypergan train /home/ubuntu/fastai-data/pokemon_img/temp -s 128x128x3 -f png -b 128 -c hypergan_pokemon --resize --sampler static_batch --sample_every 5 --save_samples --noviewer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
