{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Header](https://img00.deviantart.net/32dd/i/2015/117/7/c/redvsblue_chubbs_by_feathernotes-d461960.jpg)\n",
    "\n",
    "# Red vs. Blue Dialogue Generator (Sarge Chatbot)\n",
    "\n",
    "1. Scrape RvB transcripts from [RoosterTooths](http://roostertooths.com/transcripts.php)\n",
    "2. Train word based LSTM on scripts, starting from pretrained embeddings\n",
    "3. Predict Sarge dialogue by priming with the conversor's dialogue added to some random dialogue\n",
    "\n",
    "## Scrape Transcripts\n",
    "\n",
    " - Create empty scripts.txt file in appropriate directory beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests, os\n",
    "\n",
    "path = '/home/ubuntu/fastai-data/rvb/scripts.txt'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open(path, 'w') as f:\n",
    "    for i in range(347):\n",
    "        page = requests.get('http://roostertooths.com/transcripts.php?eid={}'.format(i+1))\n",
    "        tree = html.fromstring(page.content)\n",
    "        lines = []\n",
    "        f.write('\\n\\n'+tree.xpath('//p[@class=\"breadcrumbs\"]/a//text()')[1]\n",
    "              +'\\n'+tree.xpath('//h1//text()')[0]+'\\n\\n')\n",
    "        for row in tree.xpath('//table[@class=\"script\"]/tr'):\n",
    "            f.write(''.join(row.xpath('.//td//text()'))+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN Mixed dnn version. The header is from one version, but we link with a different version (6021, 5103))\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1902635\n",
      "total chars: 75\n"
     ]
    }
   ],
   "source": [
    "# load text\n",
    "text = open(path).read().lower()[:]\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print('total chars:', vocab_size)\n",
    "\n",
    "# create character embeddings\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 64\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(len(idx)-maxlen+1):\n",
    "    sentences.append(idx[i: i + maxlen])\n",
    "    next_chars.append(idx[i+1: i+maxlen+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 1902572\n",
      "nb chars: 1902572\n"
     ]
    }
   ],
   "source": [
    "print('nb sequences:', len(sentences))\n",
    "print('nb chars:', len(next_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 64, 30)            2250      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64, 256)           293888    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 64, 75)            19275     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 75)            0         \n",
      "=================================================================\n",
      "Total params: 840,725\n",
      "Trainable params: 840,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "# 2 layer network with 256 channels each\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length=maxlen),\n",
    "    #BatchNormalization(),\n",
    "    LSTM(256, input_shape=(n_fac,),return_sequences=True, dropout=0.001, recurrent_dropout=0.001,\n",
    "        implementation=2),\n",
    "    Dropout(0.01),\n",
    "    LSTM(256, return_sequences=True, dropout=0.001, recurrent_dropout=0.001,\n",
    "        implementation=2),\n",
    "    Dropout(0.01),\n",
    "    #LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2,\n",
    "    #    implementation=2),\n",
    "    #Dropout(0.2),\n",
    "    TimeDistributed(Dense(vocab_size)),\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='grifbot_model2.json' target='_blank'>grifbot_model2.json</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/fastai-notes/nbs/grifbot_model2.json"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save as JSON\n",
    "json_string = model.to_json()\n",
    "with open('grifbot_model2.json', 'w+') as f:\n",
    "    f.write(json_string)\n",
    "FileLink('grifbot_model2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "import random\n",
    "\n",
    "def print_example(length=800, temp=0.68):\n",
    "    seed_len=64\n",
    "    text = open(path).read().lower()[:]\n",
    "    ind = random.randint(0,len(text)-seed_len-1)\n",
    "    seed_string = text[ind:ind+seed_len]\n",
    "    for i in range(length):\n",
    "        x=np.array([char_indices[c] for c in seed_string[-seed_len:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = np.log(preds) / temp\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        print(next_char, end=\"\")\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string[seed_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LambdaCallback\n",
    "import h5py\n",
    "\n",
    "def print_callback(logs, epoch):\n",
    "    print_example()\n",
    "\n",
    "weight_dir = '/home/ubuntu/fastai-data/rvb/weights'\n",
    "weight_path = \"weights2-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(os.path.join(weight_dir, weight_path),\n",
    "                             monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.000000001)\n",
    "printer = LambdaCallback(on_epoch_end=print_callback)\n",
    "\n",
    "callbacks_list = [printer, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 427008/1902570 [=====>........................] - ETA: 10615s - loss: 0.7681 - acc: 0.7519"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "model.load_weights(os.path.join(weight_dir, 'weights2-00.hdf5'))\n",
    "history = []\n",
    "history.append(model.fit(sentences,\n",
    "                    np.expand_dims(next_chars,-1),\n",
    "                    batch_size=256,\n",
    "                    epochs=num_epochs,\n",
    "                    callbacks=callbacks_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I like how it learns Spanish exclusively from Lopez's dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_example(length=20000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
